# -*- coding: utf-8 -*-
"""data_clean.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bk3c43s2ht2b8Qmzsqrfp2JnRnCg7szR
"""

# Commented out IPython magic to ensure Python compatibility.
!ls
# %cd drive
!ls
# %cd MyDrive
# %cd Trash_Data
!ls

!pip install -r requirements.txt

!pip uninstall -y sympy
!pip install sympy

# Begin Setup
import torch
import torchvision
import torchvision.transforms as transforms
import numpy as np
import random
import os
from skimage import io

# set random seeds
torch.manual_seed(131)
np.random.seed(131)
random.seed(131)

"""Import Data"""

# Commented out IPython magic to ensure Python compatibility.
# Clone the TACO dataset repository
!git clone https://github.com/pedropro/TACO.git
# Navigate to the TACO directory
# %cd TACO
# Verify if the download script exists
!ls

!python download.py

!pip install kaggle

os.getcwd()
os.chdir('..')
os.getcwd()

!chmod 600 kaggle.json

!kaggle datasets list
!kaggle datasets download sumn2u/garbage-classification-v2
!mkdir ./train
!unzip garbage-classification-v2.zip -d train

"""# Organize TACO Data"""

# Commented out IPython magic to ensure Python compatibility.
!pwd
# %cd MyDrive
# %cd Trash_Data
# %cd TACO
# %cd data
import json
import cv2

anns_file_path = './data' + '/' + 'annotations.json'
with open('annotations.json', 'r') as f:
    dataset = json.loads(f.read())

categories = dataset['categories']
anns = dataset['annotations']
imgs = dataset['images']
nr_cats = len(categories)
nr_annotations = len(anns)
nr_images = len(imgs)

cat_names = []
super_cat_names = []
super_cat_ids = {}
nr_super_cats = 0

super_cat_last_name = ""

for cat_it in categories:
    cat_names.append(cat_it['name'])
    super_cat_name = cat_it['supercategory']
    # Adding new supercat
    if super_cat_name != super_cat_last_name:
        super_cat_names.append(super_cat_name)
        super_cat_ids[super_cat_name] = nr_super_cats
        super_cat_last_name = super_cat_name
        nr_super_cats += 1


heights = [img['height'] for img in imgs]
index = heights.index(474)
print(index)
[x, y, w, h] = anns[0]['bbox']
heights = np.array(heights)
unique_heights = np.unique(heights)
print(unique_heights)
print(imgs)
print(anns)

# Checking images
import matplotlib.pyplot as plt
print(imgs[0]['file_name'])
img1 = io.imread(imgs[0]['file_name'])

H, W, C = img1.shape
print(f"H: {H} W: {W}")

plt.figure(1)
plt.imshow(img1)
plt.axis('off')

start_point = (int(x), int(y))
end_point = (int(x + w) , int(y + h))

print(start_point)
print(end_point)

og_img = img1.copy()  # Make a copy before modifying
cv2.rectangle(og_img, start_point, end_point, 7, 8)

plt.imshow(og_img)
plt.axis('off')
plt.show()


resized = cv2.resize(img1, (640, 640))
H, W, C = resized.shape

# Resize bounding boxes
scale_x = 640 / W
scale_y = 640 / H

start_point_rs = ()
print(f"H: {H} W: {W}")

plt.figure(2)
plt.imshow(resized)
plt.axis('off')

plt.show()